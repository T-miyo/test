まだ大まかにしか把握出来ていない為、有名な機械学習モデルをメモしておく

・ロジスティック回帰	
ロジスティック回帰は、データの線形分離可能性を用いて確率をモデル化し、
分類を行うモデルです。シグモイド関数により確率を0から1の範囲に制限します。
・決定木
決定木はデータを階層的に分割して予測を行う分類・回帰モデルです。分割基準は情報利得やジニ不純度などが使われます。
・ランダムフォレスト	
ランダムフォレストは、複数の決定木を組み合わせて予測を行うアンサンブル学習法です。
データのブートストラップサンプリングとランダムな特徴の選択が特徴的です。
・K最近傍法	
K最近傍法は、新しいデータに対して、トレーニングデータの中から距離が最も近いK個のデータ点を参照して、多数決などにより予測を行います。
・サポートベクターマシン	
サポートベクターマシンは、データを高次元空間にマッピングし、
超平面によってデータを分類するモデルです。マージン最大化により最適な超平面を求めます。
・線形SVC（サポートベクターマシン）	
線形SVCは、サポートベクターマシンの一種で、データを線形超平面によって分類するモデルです。
マージン最大化により最適な超平面を求めます。
・確率的勾配降下法	
確率的勾配降下法は、最適化アルゴリズムの一つで、モデルのパラメータを最適化する手法です。
機械学習の多くのモデルで学習に利用されます。
・パーセプトロン	
パーセプトロンは、ニューラルネットワークの一種で、複数の入力に対して重み付き和を計算し、活性化関数を用いて予測を行います。
・ナイーブベイズ	
ナイーブベイズは、ベイズの定理を用いて分類を行う確率モデルです。特徴の条件付き独立性を仮定し、計算効率が高いことが特徴です。
