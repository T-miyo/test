#自転車のシェアサービスの利用者数の変化を予測する(スコア役0.42がベスト)
#利用者数には平日、週末や休日
#天候などが影響が大きいと予想

# Data Manipulation Libraries
import pandas as pd
import numpy as np

# Plotting Libraries
from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

# Machine Learning Libraries
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')
test = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')
sample = pd.read_csv('/kaggle/input/bike-sharing-demand/sampleSubmission.csv')

#countに関連深い項目をざっくり見る為にヒートマップを作製
hmap = train.corr('pearson', numeric_only=True)
sns.heatmap(hmap)

#temp、atemp天候が一番影響が高い事。登録者、未登録者はテストでは使わないデータの為削除
train_df = train.loc[:,['datetime','season', "holiday", "workingday", "weather", "temp", "atemp", "humidity", "windspeed", "count"]]

#各項目の値の出現回数を図示
# Columns for which histograms need to be plotted
numeric_cols = ['season', 'weather', 'humidity', 'holiday', 'workingday', 'temp', 'atemp', 'windspeed']

# Define the figure size
plt.figure(figsize=(20, 15))

# Loop through the numeric columns and plot histograms
for i, col in enumerate(numeric_cols, start=1):
    plt.subplot(4, 2, i)
    train_df[col].plot.hist(bins=10, color='C'+str(i), label=f'Histogram of {col.capitalize()}', edgecolor='black')
    plt.legend(loc='best')

# Adjust the layout
plt.tight_layout()

#四季の違いでの利用者数の違いがあるかをチェック。春以外は近い利用者数
#train_df.loc[:,['season', 'count']].groupby('season').sum()の「.」はすべてのデータを使用する意味。
# Calculate count_season using groupby and join
by_season = train_df.loc[:,['season', 'count']].groupby('season').sum()
by_season['count'] = by_season['count'].astype(int)  # Convert the sum to integer
train_df = train_df.merge(by_season, how='left', on='season', suffixes=('', '_season'))

# Plot the count_season
by_season.plot(kind='barh')
plt.grid(True)
plt.show()

#１時間毎の利用者数を抽出して図示(その日が週末でも休日でもないかどうかもworkingdayで判断)
by_hour = train_df.groupby(['hour', 'workingday'])['count'].agg('sum').unstack()
by_hour.head(10)
by_hour.plot(kind='bar', figsize=(15, 5), width=0.8, grid=True)
plt.tight_layout()
plt.show()
#より多くの情報を得られる(四分位や中央値など)箱ひげ図の読み取りのトレーニングの兼ねて箱ひげ図で表示
#平日や仕事をされてる方が多い日は全体的に利用者は少なく、7から9時、17 ～ 19 時は利用者数が多く、
#0 ～ 6 時および 20 ～ 24 時は利用者数が少ない事が分かる
plt.figure(figsize=(18, 5))
sns.boxplot(x=train_df['hour'], y=train_df['count'])
plt.ylabel('Count of Users')
plt.title("Boxplot of Count grouped by hour");

#大まかに思いつくシチュエーションを確認したので年月日を分析できる形に変更する。曜日の判断も出来る様に追加
train['datetime'] = pd.to_datetime(train['datetime'])
train['year'] = train['datetime'].dt.year
train['month'] = train['datetime'].dt.month
#train['day'] =  train['datetime'].dt.day
train['hour'] = train['datetime'].dt.hour
train['dow'] = train['datetime'].dt.dayofweek

train.drop(columns=['casual', 'registered', 'datetime'], inplace=True)
#train.drop(columns=['casual', 'registered'], inplace=True)
test['datetime'] = pd.to_datetime(test['datetime'])
test['year'] = test['datetime'].dt.year
test['month'] = test['datetime'].dt.month
#test['day'] =  test['datetime'].dt.day
test['hour'] = test['datetime'].dt.hour
test['dow'] = test['datetime'].dt.dayofweek

test.drop(columns=['datetime'], inplace=True)

#トレーニングデータをトレーニングと検証用に分ける
X = train.drop(columns = ['count'], axis=1)
y = train['count']
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)

#スコアを確認する為の関数を作成
def rmsle(y_true, y_pred, convertExp=True):
    if convertExp:
        y_true = np.exp(y_true)
        y_pred = np.exp(y_pred)
     
    log_true = np.nan_to_num(np.log(y_true+1))
    log_pred = np.nan_to_num(np.log(y_pred+1))
    
    output = np.sqrt(np.mean((log_true - log_pred)**2))
    return output

♯ランダムフォレストを使用
model = RandomForestRegressor()

params = {'n_estimators': [100, 150, 200], 
              'max_depth': [3, 4, 5], 
              'learning_rate': [0.05, 0.1, 0.15]}

rmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False)

log_y = np.log(y_train)
model.fit(X_train, log_y)
#print(gridsearch_model.best_params_)

log_y_2 = np.log(y_valid)
predictions = model.predict(X_valid)
print(f'RMSLE: {rmsle(log_y_2, predictions, True):.5f}')

♯学習後テストデータで予測してcsvに指定の形式で作成
test_predictions = model.predict(test)
sample['count'] = np.exp(test_predictions)
sample.to_csv('submission.csv', index=False)
