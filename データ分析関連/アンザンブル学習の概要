アンザンブル学習の代表的な手法
①バギング
異なるデータを抽出（ブートストラップ法）して、複数の異なるモデル（弱学習器）を作成する。
その後、作成した複数のモデルの平均を最終的なモデルとする。

○特徴
・バリアンスを小さくすることができる。
・並列処理のため、学習時間が短い。
（ブーストラップ法でデータを複数抽出して、複数同時に学習する）

○代表的なモデル
ランダムフォレスト


②ブースティング
同じデータに対して何回も学習をし、より精度の高いモデルを構築していく。

○特徴
・バイアスを小さくすることができる。
（バギングよりも良い精度が見込める）
・直列処理のため、学習時間が長い。
（モデルの結果をより改善するモデルを繰り返し構築していく）

○代表的なモデル
XGBoost・LightGBM


③スタッキング
複数のモデルを組み合わせてモデルを作成する。

具体的に説明すると、最初に「重回帰分析」、「ランダムフォレスト」、「LightGBM」で予測した値を特徴量として、重回帰分析で予測するという流れになります。

つまり、３つのモデルで予測された3つの予測値が、重回帰分析の入力値になるということ。

どんなモデルを組み合わせるか悩むかと思いますが、決定木系（ランダムフォレスト、XGBoost等）と回帰系（重回帰分析）を組み合わせるのが一般的です。
（異なる系統のモデルを組み合わせることで、単体では発見できない特徴を補ってくれる可能性がある）

○特徴
・予測精度が向上する。
（基本的に単体モデルよりも良い精度が出る）
・結果の解釈、分析が難しくなる。
・学習時間が長くなる
