https://www.salesanalytics.co.jp/datascience/datascience145/#i-2
上記のHPの記載を参照して実装してみた

特徴量の項目の選択を

フィルタ法では、統計のテクニックを用いて各特徴の「予測に使える度合」を点数化します。
点数をもとに特徴にランク付けを行い、予測に使うか否かをそれぞれ決定
点数を決めるのにもいくつか方法があり、特徴と予測対象の関係性を見て決める方法もあれば、
特徴だけを見て統計的に決める方法もあります。
欠点としては、特徴を1つずつしか見られないので、複数の特徴量の併用効果は考慮されないことが挙げられます

ラッパー法では複数の特徴を同時に使って予測精度の検証を行い、
精度が最も高くなるような特徴量の組み合わせを探索していきます。
様々な組み合わせでそれぞれ学習を行わせ、その学習結果をもとに組み合わせに優劣をつけていきます

組み込み法はフィルタ法とラッパー法の2つの強みを掛け合わせたような手法で、
機械学習モデルが学習の一環として特徴の選択を行います
上2つの方法と違い、そもそもの学習アルゴリズムに特徴量選択が組み込まれているので、
学習と特徴量選択を同時に行うことができます。
使われるアルゴリズムですが「ラッソ回帰（LASSO Linear Regression）」や「決定木」などがあります
