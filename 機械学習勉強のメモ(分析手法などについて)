手探りでチュートリアルのコンペなどで公開されてるコードをみる
Kaggleなどのデータ分析コンペでテーブルデータを扱う場合、最近は取りあえずLightGBMを利用する場合が多い

理由
LightGBMは、欠損値を含む特徴量も入力として扱うことが可能です。
線形回帰モデルのロジスティック回帰などを用いる場合は欠損値を補完する処理が必要ですが、LightGBMを採用することでその処理を割愛できる
LightGBMは、「決定木」を基にした機械学習アルゴリズムで一つの特徴量に対し一つの閾値を定め、次々と条件分岐していきながら予測値を決定

LightGBMは、特徴量の重要度を計算する機能があります。特徴量の重要度を見ることで、次なる特徴量エンジニアリングの手を考えることが可能
LightGBMは過去のKaggleでの実績からも分かる通り、テーブルデータを扱う上で優秀な機械学習アルゴリズムです。最初からLightGBMを試しておくことで、手戻りの可能性を減らすことができる
LightGBMは、比較的大きなデータも高速に扱える利点があります

トレーニングに使うデータの状態を確認する
ある変数が正規分布しているか否かを知りたい時にShapiro-Wilk（シャピロ-ウィルク）検定を使います。
データが正規分布しているかは統計学において重要で、例えば様々な統計的検定や推定手法がその仮定を前提として行われます。
名義尺度や少数のカテゴリーを持つ順序尺度のデータにシャピロ-ウィルク検定が適していません。
これらの尺度ではデータの順序や間隔が一定でないため、正規分布の仮定が成立しにくいためです。
