#実務で関われない為、実践レベルのデータ分析を行うための基本的な作業を学ぶ事が目的
#pythonでpandasを使用して作業しながらやってみる
#Label Encoding
文字列データはそのまま学習に使うことができません。
そこで、文字列データに対してLabel Encodingを行います。
Label Encodingとは、文字列等のデータを数値のラベルに変換することを指します。

1、csvファイルのデータをディレクトリ設定して読み込んで「home_data.describe()」で表示
import pandas as pd

# Path of the file to read
iowa_file_path = '../input/home-data-for-ml-course/train.csv'

# Fill in the line below to read the file into a variable home_data
home_data = pd.read_csv(iowa_file_path)

# Call line below with no argument to check that you've loaded the data correctly
step_1.check()

# Print summary statistics in next line
home_data.describe()

2、表示されたデータから直接数値を設定
# What is the average lot size (rounded to nearest integer)?
avg_lot_size = 10517

# As of today, how old is the newest home (current year - the date in which it was built)
newest_home_age = 14

# Checks your answers
step_2.check()

3、「melbourne_data.columns」でデータの項目を表示して使う項目を確認
(読み込んだデータフレーム).columns

4、実践では欠損値がある為考慮した処理が必要になる
演習では「melbourne_data = melbourne_data.dropna(axis=0)」で欠損を削除している

5、予測ターゲットをyに設定する
今回は住宅価格なので「y = melbourne_data.Price」

6、予測で使用する特徴の項目(列)を選択する
「melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
　X = melbourne_data[melbourne_features]」

7、「X.describe()」と「X.head()」で住宅価格を予測するために使用するデータを簡単に確認
　headメゾットは先頭から5つまでのデータを表示

8、scikit-learn ライブラリを使用してモデルを作成
「from sklearn.tree import DecisionTreeRegressor

# Define model. Specify a number for random_state to ensure same results each run
melbourne_model = DecisionTreeRegressor(random_state=1)

# Fit model
melbourne_model.fit(X, y)」
チュートリアルの為、トレーニングデータの最初の数行に対して予測してみる(実際には、すでに価格がわかっている住宅ではなく、市場に登場する新しい住宅を予測する必要がある)
「print("Making predictions for the following 5 houses:")
print(X.head())
print("The predictions are")
print(melbourne_model.predict(X.head()))」

9、絶対平均誤差を使って構築したモデルを評価する
「from sklearn.metrics import mean_absolute_error

predicted_home_prices = melbourne_model.predict(X)
mean_absolute_error(y, predicted_home_prices)」

10、データはトレーニングデータと検証データに分ける
「from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
# Define model
melbourne_model = DecisionTreeRegressor()
# Fit model
melbourne_model.fit(train_X, train_y)

# get predicted prices on validation data
val_predictions = melbourne_model.predict(val_X)
print(mean_absolute_error(val_y, val_predictions))」

11、過学習と過小学習を制御する
　　for ループを使用して、max_leaf_nodes のさまざまな値で構築されたモデルの精度を比較
「from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor

def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)
# compare MAE with differing values of max_leaf_nodes
for max_leaf_nodes in [5, 50, 500, 5000]:
    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))」

12、Kaggle コンテストの予測を作成して送信してみる
　　まず、以下のコード セルを実行して、コード チェックとデータセットのファイルパスを設定
「# Set up code checking
from learntools.core import binder
binder.bind(globals())
from learntools.machine_learning.ex7 import *

# Set up filepaths
import os
if not os.path.exists("../input/train.csv"):
    os.symlink("../input/home-data-for-ml-course/train.csv", "../input/train.csv")  
    os.symlink("../input/home-data-for-ml-course/test.csv", "../input/test.csv")」

「# Import helpful libraries
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

# Load the data, and separate the target
iowa_file_path = '../input/train.csv'
home_data = pd.read_csv(iowa_file_path)
y = home_data.SalePrice

# Create X (After completing the exercise, you can return to modify this line!)
features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']

# Select columns corresponding to features, and preview the data
X = home_data[features]
X.head()

# Split into validation and training data
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

# Define a random forest model
rf_model = RandomForestRegressor(random_state=1)
rf_model.fit(train_X, train_y)
rf_val_predictions = rf_model.predict(val_X)
rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)

print("Validation MAE for Random Forest Model: {:,.0f}".format(rf_val_mae))」

13、ランダム フォレスト モデルを構築し、それをすべての X と y でトレーニング

14、コードセルを実行して、コンテストに提出するために使用できる予測を含む CSV ファイルを生成
「# Run the code to save predictions in the format used for competition scoring

output = pd.DataFrame({'Id': test_data.Id,
                       'SalePrice': test_preds})
output.to_csv('submission.csv', index=False)」

15、欠損値の補完が完了したら、特徴量の変換処理を行います。
特徴量の変換処理を行う理由は、文字列であるカテゴリ変数は、機械学習のモデルで解釈できないためです。
そのため、文字列データを数値データに変換する必要があります。
変換方法はいくつか存在しますが、ここでは以下の2つの変換手法を使用
one-hot encoding：カテゴリ変数に「大小、良し悪し、高い低い」と言った尺度がある
one-hotエンコーディングは、pandas.DataFrameを使用します。
pandas.DataFrameによるone-hot encodingは、デフォルトでデータ型がobjectまたはcategoryとなっている列の全データをone-hot encoding処理する仕様となっています。
一方、数値（int, float）やbool型の列は、デフォルトでone-hot encodingの変更対象外となります。
その為、先にlabel encodingをしておくと楽になる
label encoding：上記以外
データを1つ1つ確認しながら、label encodingの対象となるデータを抽出

16、LightGBMによる学習と予測
ここまででデータの準備、モデルの選定、モデルの評価方法の明確化が完了
モデルの選定パートで適用するモデルとして選定した「LightGBM」の実装
”木構造を用いた勾配ブースティングのフレームワーク”
